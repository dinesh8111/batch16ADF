{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea42ee03-c31c-4a5d-9938-a720bf03b19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ðŸ“˜ Delta Live Tables (DLT)\n",
    "\n",
    "## 1. What is Delta Live Tables?\n",
    "- DLT is a **declarative ETL framework** in Databricks for building **reliable data pipelines**.\n",
    "- You define tables/views with simple SQL or Python, Databricks **automatically manages execution, dependencies, retries, and monitoring**.\n",
    "- Supports both **batch** and **streaming** pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Key Features\n",
    "- âœ… **Declarative**: You define *what* you want (tables/views), not *how* to run.  \n",
    "- âœ… **Auto Dependency Management**: DLT figures out the order of execution.  \n",
    "- âœ… **Data Quality**: Built-in **expectations** (data validation).  \n",
    "- âœ… **Auto Scaling**: Manages cluster resources.  \n",
    "- âœ… **Monitoring**: In-built UI with lineage & metrics.  \n",
    "- âœ… **SCD Support**: Built-in support for Slowly Changing Dimensions (Type 2).  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Core Concepts\n",
    "### ðŸ”¹ Live Table\n",
    "- A managed Delta table maintained by DLT.\n",
    "- Defined with:\n",
    "```sql\n",
    "CREATE OR REFRESH LIVE TABLE customers_bronze AS\n",
    "SELECT * FROM cloud_files(\"/mnt/raw/customers\", \"csv\", map(\"header\",\"true\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29acd135-f218-45cf-838c-8cfa0c1c41a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ðŸ”¹ Streaming Live Table\n",
    "\n",
    "A streaming Delta table maintained by DLT.\n",
    "New data appended continuously.\n",
    "\n",
    "CREATE OR REFRESH STREAMING LIVE TABLE customers_bronze AS\n",
    "SELECT * FROM cloud_files(\"/mnt/raw/customers\", \"csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "082eedd0-31d9-4019-86fe-8bcb03948af2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ðŸ”¹ Live View\n",
    "\n",
    "Logical view (not materialized).\n",
    "Used to transform before writing into tables.\n",
    "\n",
    "CREATE OR REFRESH LIVE VIEW customers_silver AS\n",
    "SELECT DISTINCT * FROM LIVE.customers_bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c981f8f8-8bd4-4c5a-9315-85ddc403de00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ðŸ”¹ Expectations (Data Quality Rules)\n",
    "\n",
    "Validate data with expectations.\n",
    "Can log, drop, or fail pipeline if rule is broken.\n",
    "\n",
    "CREATE OR REFRESH LIVE TABLE customers_silver\n",
    "TBLPROPERTIES (\"quality\" = \"silver\")\n",
    "AS\n",
    "SELECT *\n",
    "FROM LIVE.customers_bronze\n",
    "EXPECT (amount > 0) ON VIOLATION DROP ROW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06c62e4c-ad67-464c-ae79-0224139f9ee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "4. Data Quality Pipeline Layers\n",
    "\n",
    "Bronze â†’ Raw ingestion (from Auto Loader, Kafka, etc.)\n",
    "Silver â†’ Cleaned, filtered, deduplicated data\n",
    "Gold â†’ Aggregations, business KPIs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e724c05-96a0-44df-8eb1-e40e659ec480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "5. SCD Type 2 (Slowly Changing Dimensions)\n",
    "DLT provides APPLY CHANGES INTO syntax for SCD2:\n",
    "    \n",
    "APPLY CHANGES INTO LIVE.customers_scd2\n",
    "FROM LIVE.customers_silver\n",
    "KEYS (customer_id)\n",
    "SEQUENCE BY update_timestamp\n",
    "STORED AS SCD TYPE 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62ee6bc3-ef36-4ddb-a404-ee32eda57c20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "6. Python API\n",
    "Using decorators:\n",
    "import dlt\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "@dlt.table\n",
    "def customers_bronze():\n",
    "    return spark.readStream.format(\"cloudFiles\") \\\n",
    "        .option(\"cloudFiles.format\", \"csv\") \\\n",
    "        .load(\"/mnt/raw/customers\")\n",
    "\n",
    "@dlt.view\n",
    "def customers_silver():\n",
    "    return dlt.read(\"customers_bronze\").dropDuplicates([\"customer_id\"])\n",
    "\n",
    "@dlt.table\n",
    "def customers_gold():\n",
    "    return dlt.read(\"customers_silver\").groupBy(\"city\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76eaee5f-e57f-449c-8cc9-e29e9b854d8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "7. Deployment\n",
    "\n",
    "DLT pipelines are deployed via the Pipelines UI or Databricks REST API.\n",
    "\n",
    "Options:\n",
    "Continuous mode â†’ Keeps running (streaming).\n",
    "Triggered mode â†’ Runs once (batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e8004bf-6812-4f39-b63e-28e75f1a0393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "8. Why DLT?\n",
    "\n",
    "Simplifies pipeline development â†’ less boilerplate.\n",
    "Ensures data quality & lineage automatically.\n",
    "Ideal for medallion architecture (bronze â†’ silver â†’ gold).\n",
    "Integrates seamlessly with Auto Loader and Delta Lake."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dlt_theory",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
